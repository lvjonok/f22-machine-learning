{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 14:12:49.120596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-13 14:12:49.659618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:49.659653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-13 14:12:49.762221: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-13 14:12:51.541063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:51.541204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:51.541217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 14:12:54.869476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 14:12:54.870140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.870345: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.870515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.870671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.870825: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.871003: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.871162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.871363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-11-13 14:12:54.871401: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-13 14:12:54.875292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set up dataset from triple_mnist/train directory\n",
    "train_ds = tf.data.Dataset.list_files('triple_mnist/train/*/*')\n",
    "test_ds = tf.data.Dataset.list_files('triple_mnist/test/*/*')\n",
    "val_ds = tf.data.Dataset.list_files('triple_mnist/val/*/*')\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # for part in parts:\n",
    "\n",
    "    number = parts[-2]\n",
    "    number = tf.strings.to_number(number, out_type=tf.int32)\n",
    "    # get digits of this number\n",
    "    digits = [number // 100, (number // 10) % 10, number % 10]\n",
    "\n",
    "    # # encode each digit as a one-hot vector and merge them into a single vector\n",
    "    # digits = [tf.one_hot(digit, 10) for digit in digits]\n",
    "    # digits = tf.concat(digits, axis=0)\n",
    "\n",
    "    # # convert digits to tensor type\n",
    "    # digits = tf.cast(digits, tf.float32)\n",
    "    # # reshape digits to (30,)\n",
    "    # digits = tf.reshape(digits, (-1, 30,))\n",
    "    digits = tf.reshape(digits, (-1, 3,))\n",
    "\n",
    "    # print raw value for parts as string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(img)\n",
    "    # flatten image\n",
    "    # img = tf.reshape(img, (-1, 7056,))\n",
    "    # transpose image\n",
    "    return img, digits\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.map(\n",
    "    process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.map(\n",
    "    process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (84, 84, 1)\n",
      "Label:  [[3 2 8]]\n",
      "label shape:  (1, 3)\n",
      "Number:  [[3 2 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/.local/lib/python3.8/site-packages/matplotlib/text.py:1223: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe81e56a190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "image, label = next(iter(train_ds))\n",
    "print(\"Image shape: \", image.numpy().shape)\n",
    "print(\"Label: \", label.numpy())\n",
    "\n",
    "# convert label into 3digit number\n",
    "label = label.numpy()\n",
    "print(\"label shape: \", label.shape)\n",
    "# get inidices of 1s in each digit\n",
    "\n",
    "print(\"Number: \", label)\n",
    "plt.title(label)\n",
    "\n",
    "# show image\n",
    "image = image.numpy()\n",
    "image = np.reshape(image, (84, 84))\n",
    "plt.imshow(image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy model from first assignment\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "\n",
    "ann = keras.Sequential(\n",
    "    [\n",
    "        Conv2D(filters=32, kernel_size=(2, 2), activation='relu',\n",
    "               padding=\"Same\", input_shape=(84, 84, 1)),\n",
    "        Conv2D(filters=32, kernel_size=(2, 2), activation='relu',\n",
    "               padding=\"Same\"),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu',\n",
    "               padding=\"Same\"),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu',\n",
    "               padding=\"Same\"),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "       #  Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation='softmax')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 84, 84, 32)        160       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 84, 84, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 42, 42, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 42, 42, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 21, 21, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 21, 21, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 28224)             0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28224)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 84675     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144,387\n",
      "Trainable params: 144,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile the model\n",
    "ann.compile(optimizer=optimizer,\n",
    "            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "ann.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 4540/64000 [=>............................] - ETA: 11:05 - loss: 0.0000e+00 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m  \u001b[39m# Turn epochs to 30 to get 0.9967 accuracy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m86\u001b[39m\n\u001b[0;32m---> 10\u001b[0m history \u001b[39m=\u001b[39m ann\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[1;32m     11\u001b[0m                   batch_size\u001b[39m=\u001b[39;49mbatch_size, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49mval_ds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set a learning rate annealer\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "epochs = 30  # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86\n",
    "history = ann.fit(train_ds,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_data=val_ds, callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
