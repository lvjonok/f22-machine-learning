{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Instructions\n",
    "- Your submission should be the `.ipynb` file with your name,\n",
    "  like `YusufMesbah.ipynb`. it should include the answers to the questions in\n",
    "  markdown cells.\n",
    "- You are expected to follow the best practices for code writing and model\n",
    "training. Poor coding style will be penalized.\n",
    "- You are allowed to discuss ideas with your peers, but no sharing of code.\n",
    "Plagiarism in the code will result in failing. If you use code from the\n",
    "internet, cite it.\n",
    "- If the instructions seem vague, use common sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 1: ANN (30%)\n",
    "For this task, you are required to build a fully connect feed-forward ANN model\n",
    "for a multi-label regression problem.\n",
    "\n",
    "For the given data, you need do proper data preprocessing, design the ANN model,\n",
    "then fine-tune your model architecture (number of layers, number of neurons,\n",
    "activation function, learning rate, momentum, regularization).\n",
    "\n",
    "For evaluating your model, do $80/20$ train test split.\n",
    "\n",
    "### Data\n",
    "You will be working with the data in `Task 1.csv` for predicting students'\n",
    "scores in 3 different exams: math, reading and writing. The columns include:\n",
    " - gender\n",
    " - race\n",
    " - parental level of education\n",
    " - lunch meal plan at school\n",
    " - whether the student undertook the test preparation course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>40</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>group E</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group B</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group E</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0    male        group A                 high school      standard   \n",
       "1  female        group D            some high school  free/reduced   \n",
       "2    male        group E                some college  free/reduced   \n",
       "3    male        group B                 high school      standard   \n",
       "4    male        group E          associate's degree      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0               completed          67             67             63  \n",
       "1                    none          40             59             55  \n",
       "2                    none          59             60             50  \n",
       "3                    none          77             78             68  \n",
       "4               completed          78             73             68  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Task 1.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  race/ethnicity  parental level of education  lunch  \\\n",
       "0     1.0             0.0                          2.0    1.0   \n",
       "1     0.0             3.0                          5.0    0.0   \n",
       "2     1.0             4.0                          4.0    0.0   \n",
       "3     1.0             1.0                          2.0    1.0   \n",
       "4     1.0             4.0                          0.0    1.0   \n",
       "\n",
       "   test preparation course  math score  reading score  writing score  \n",
       "0                      0.0          67             67             63  \n",
       "1                      1.0          40             59             55  \n",
       "2                      1.0          59             60             50  \n",
       "3                      1.0          77             78             68  \n",
       "4                      0.0          78             73             68  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df[\"gender\"] = OrdinalEncoder().fit_transform(df[\"gender\"].values.reshape(-1,1))\n",
    "df[\"race/ethnicity\"] = OrdinalEncoder().fit_transform(df[\"race/ethnicity\"].values.reshape(-1,1))\n",
    "df[\"parental level of education\"] = OrdinalEncoder().fit_transform(df[\"parental level of education\"].values.reshape(-1,1))\n",
    "df[\"lunch\"] = OrdinalEncoder().fit_transform(df[\"lunch\"].values.reshape(-1,1))\n",
    "df[\"test preparation course\"] = OrdinalEncoder().fit_transform(df[\"test preparation course\"].values.reshape(-1,1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['math score', 'reading score', 'writing score']]\n",
    "values = df.drop(['math score', 'reading score', 'writing score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 5), (200, 5), (800, 3), (200, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4894.7036 - mae: 68.3112 - val_loss: 4756.7705 - val_mae: 67.2187\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4855.6416 - mae: 68.0214 - val_loss: 4714.5938 - val_mae: 66.9001\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4814.8926 - mae: 67.7168 - val_loss: 4670.3755 - val_mae: 66.5643\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4771.5361 - mae: 67.3911 - val_loss: 4622.4976 - val_mae: 66.1984\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4724.1045 - mae: 67.0333 - val_loss: 4569.4834 - val_mae: 65.7906\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4670.9370 - mae: 66.6279 - val_loss: 4511.0288 - val_mae: 65.3382\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4611.1904 - mae: 66.1729 - val_loss: 4444.4775 - val_mae: 64.8204\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4543.3809 - mae: 65.6487 - val_loss: 4368.7412 - val_mae: 64.2269\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4465.3896 - mae: 65.0451 - val_loss: 4281.8135 - val_mae: 63.5391\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4373.3916 - mae: 64.3286 - val_loss: 4177.3369 - val_mae: 62.7044\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4262.2207 - mae: 63.4412 - val_loss: 4047.9375 - val_mae: 61.6549\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 4127.3091 - mae: 62.3601 - val_loss: 3894.0078 - val_mae: 60.3762\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3970.5669 - mae: 61.0580 - val_loss: 3722.3628 - val_mae: 58.9094\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3799.4409 - mae: 59.6166 - val_loss: 3541.3562 - val_mae: 57.3159\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3621.6460 - mae: 58.0564 - val_loss: 3354.4390 - val_mae: 55.6174\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3438.5188 - mae: 56.4156 - val_loss: 3166.0659 - val_mae: 53.8449\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3254.5586 - mae: 54.6977 - val_loss: 2976.3276 - val_mae: 51.9917\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3068.9846 - mae: 52.9142 - val_loss: 2789.5000 - val_mae: 50.0937\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2886.5020 - mae: 51.0820 - val_loss: 2604.2776 - val_mae: 48.1285\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2705.9565 - mae: 49.2060 - val_loss: 2424.3296 - val_mae: 46.1295\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2530.0835 - mae: 47.3162 - val_loss: 2250.1660 - val_mae: 44.0977\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2360.1157 - mae: 45.3787 - val_loss: 2082.3384 - val_mae: 42.0564\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2196.7400 - mae: 43.4457 - val_loss: 1922.0471 - val_mae: 40.0048\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2039.9170 - mae: 41.4997 - val_loss: 1771.5710 - val_mae: 37.9882\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1891.7332 - mae: 39.6297 - val_loss: 1630.6344 - val_mae: 35.9962\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1752.6174 - mae: 37.7550 - val_loss: 1499.3734 - val_mae: 34.0607\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1622.1609 - mae: 35.9699 - val_loss: 1378.8522 - val_mae: 32.2303\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1501.9918 - mae: 34.2804 - val_loss: 1267.7783 - val_mae: 30.5356\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1390.8180 - mae: 32.6338 - val_loss: 1167.5540 - val_mae: 28.9713\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1289.8972 - mae: 31.1340 - val_loss: 1077.1458 - val_mae: 27.5180\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1198.5347 - mae: 29.7450 - val_loss: 996.5965 - val_mae: 26.2316\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1116.2302 - mae: 28.4754 - val_loss: 926.1544 - val_mae: 25.0808\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1042.9623 - mae: 27.3183 - val_loss: 865.1732 - val_mae: 24.0287\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 978.0851 - mae: 26.3054 - val_loss: 813.2479 - val_mae: 23.1300\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 922.6595 - mae: 25.4374 - val_loss: 767.6315 - val_mae: 22.3596\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 872.9647 - mae: 24.6622 - val_loss: 730.4222 - val_mae: 21.7505\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 830.9551 - mae: 23.9882 - val_loss: 699.2687 - val_mae: 21.2487\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 794.8583 - mae: 23.4164 - val_loss: 673.8112 - val_mae: 20.8839\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 764.7022 - mae: 22.9318 - val_loss: 652.6562 - val_mae: 20.5779\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 738.5612 - mae: 22.4997 - val_loss: 636.1344 - val_mae: 20.3542\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 716.4563 - mae: 22.1241 - val_loss: 623.2719 - val_mae: 20.1792\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 698.4782 - mae: 21.8198 - val_loss: 612.7844 - val_mae: 20.0440\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 683.4611 - mae: 21.5615 - val_loss: 604.0809 - val_mae: 19.9266\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 669.9264 - mae: 21.3282 - val_loss: 597.5223 - val_mae: 19.8347\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 659.1515 - mae: 21.1457 - val_loss: 591.9015 - val_mae: 19.7501\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 649.6555 - mae: 20.9732 - val_loss: 587.3071 - val_mae: 19.6784\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 641.1093 - mae: 20.8282 - val_loss: 582.9967 - val_mae: 19.6114\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 634.0304 - mae: 20.6994 - val_loss: 579.5237 - val_mae: 19.5669\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 627.2816 - mae: 20.5753 - val_loss: 576.0568 - val_mae: 19.5169\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 621.0934 - mae: 20.4651 - val_loss: 572.4654 - val_mae: 19.4572\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 615.3509 - mae: 20.3598 - val_loss: 568.9313 - val_mae: 19.3947\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 610.1940 - mae: 20.2667 - val_loss: 566.0579 - val_mae: 19.3505\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 605.1652 - mae: 20.1746 - val_loss: 562.8185 - val_mae: 19.2989\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 600.0753 - mae: 20.0785 - val_loss: 559.3387 - val_mae: 19.2388\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 595.4390 - mae: 19.9905 - val_loss: 555.7308 - val_mae: 19.1801\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 590.8834 - mae: 19.9052 - val_loss: 551.7038 - val_mae: 19.1095\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 586.3592 - mae: 19.8191 - val_loss: 548.3751 - val_mae: 19.0553\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 582.1902 - mae: 19.7380 - val_loss: 545.3856 - val_mae: 19.0087\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 577.4672 - mae: 19.6501 - val_loss: 541.1675 - val_mae: 18.9287\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 573.3192 - mae: 19.5752 - val_loss: 537.1248 - val_mae: 18.8561\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 569.0873 - mae: 19.4953 - val_loss: 533.2689 - val_mae: 18.7878\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 565.1859 - mae: 19.4207 - val_loss: 530.6691 - val_mae: 18.7498\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 560.6585 - mae: 19.3322 - val_loss: 526.3889 - val_mae: 18.6690\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 556.7540 - mae: 19.2602 - val_loss: 522.1952 - val_mae: 18.5894\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 552.7233 - mae: 19.1843 - val_loss: 518.4670 - val_mae: 18.5219\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 548.6383 - mae: 19.1055 - val_loss: 515.1787 - val_mae: 18.4645\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 544.6561 - mae: 19.0332 - val_loss: 511.1495 - val_mae: 18.3873\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 540.8199 - mae: 18.9599 - val_loss: 507.1653 - val_mae: 18.3113\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 536.9305 - mae: 18.8876 - val_loss: 503.8250 - val_mae: 18.2502\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 533.2696 - mae: 18.8175 - val_loss: 500.5378 - val_mae: 18.1911\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 529.3245 - mae: 18.7436 - val_loss: 496.0417 - val_mae: 18.1009\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 525.5770 - mae: 18.6705 - val_loss: 492.6815 - val_mae: 18.0386\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 521.8443 - mae: 18.6022 - val_loss: 489.1326 - val_mae: 17.9721\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 518.1810 - mae: 18.5296 - val_loss: 485.4915 - val_mae: 17.9047\n",
      "Epoch 75/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 514.5663 - mae: 18.4603 - val_loss: 481.9722 - val_mae: 17.8398\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 511.0511 - mae: 18.3927 - val_loss: 478.2989 - val_mae: 17.7720\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 507.5998 - mae: 18.3267 - val_loss: 474.7270 - val_mae: 17.7066\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 503.9135 - mae: 18.2531 - val_loss: 472.0876 - val_mae: 17.6621\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 500.6279 - mae: 18.1882 - val_loss: 468.8822 - val_mae: 17.6071\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 497.1991 - mae: 18.1217 - val_loss: 465.1351 - val_mae: 17.5376\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 493.7567 - mae: 18.0541 - val_loss: 462.1254 - val_mae: 17.4843\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 490.5602 - mae: 17.9923 - val_loss: 458.2548 - val_mae: 17.4104\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 487.1765 - mae: 17.9252 - val_loss: 455.3795 - val_mae: 17.3605\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 484.0161 - mae: 17.8620 - val_loss: 452.1566 - val_mae: 17.3021\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 480.8158 - mae: 17.7974 - val_loss: 449.4116 - val_mae: 17.2553\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 477.8885 - mae: 17.7420 - val_loss: 445.3778 - val_mae: 17.1760\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 474.5093 - mae: 17.6730 - val_loss: 443.3208 - val_mae: 17.1440\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 471.5490 - mae: 17.6118 - val_loss: 440.8437 - val_mae: 17.1019\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 468.6513 - mae: 17.5555 - val_loss: 436.8871 - val_mae: 17.0212\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 465.5045 - mae: 17.4921 - val_loss: 434.5475 - val_mae: 16.9811\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 462.5951 - mae: 17.4308 - val_loss: 431.8433 - val_mae: 16.9310\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 459.6780 - mae: 17.3715 - val_loss: 428.6434 - val_mae: 16.8669\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 456.8101 - mae: 17.3145 - val_loss: 426.2126 - val_mae: 16.8207\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 454.0720 - mae: 17.2577 - val_loss: 422.9806 - val_mae: 16.7545\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 451.2376 - mae: 17.1991 - val_loss: 420.7228 - val_mae: 16.7102\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 448.5301 - mae: 17.1442 - val_loss: 417.5627 - val_mae: 16.6436\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 445.9283 - mae: 17.0926 - val_loss: 415.5913 - val_mae: 16.6092\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 443.1237 - mae: 17.0324 - val_loss: 412.6344 - val_mae: 16.5482\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 440.5168 - mae: 16.9784 - val_loss: 410.3120 - val_mae: 16.5024\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 438.0677 - mae: 16.9274 - val_loss: 407.0111 - val_mae: 16.4311\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 435.5580 - mae: 16.8737 - val_loss: 405.6007 - val_mae: 16.4084\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 432.8123 - mae: 16.8156 - val_loss: 402.9952 - val_mae: 16.3529\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 430.3934 - mae: 16.7666 - val_loss: 399.9163 - val_mae: 16.2829\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 427.9424 - mae: 16.7147 - val_loss: 398.1960 - val_mae: 16.2512\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 425.5095 - mae: 16.6635 - val_loss: 396.1398 - val_mae: 16.2097\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 423.1176 - mae: 16.6139 - val_loss: 393.4803 - val_mae: 16.1508\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 420.8085 - mae: 16.5655 - val_loss: 390.6421 - val_mae: 16.0848\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 418.3893 - mae: 16.5150 - val_loss: 388.6388 - val_mae: 16.0425\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 416.0871 - mae: 16.4667 - val_loss: 387.0687 - val_mae: 16.0123\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 413.8485 - mae: 16.4191 - val_loss: 385.2496 - val_mae: 15.9750\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 411.5988 - mae: 16.3708 - val_loss: 383.3852 - val_mae: 15.9351\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 409.4417 - mae: 16.3264 - val_loss: 380.8561 - val_mae: 15.8744\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 407.4003 - mae: 16.2820 - val_loss: 378.2806 - val_mae: 15.8138\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 405.2510 - mae: 16.2382 - val_loss: 377.6682 - val_mae: 15.8069\n",
      "Epoch 115/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 402.9149 - mae: 16.1882 - val_loss: 374.5393 - val_mae: 15.7306\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 400.7495 - mae: 16.1439 - val_loss: 372.6099 - val_mae: 15.6884\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 398.6125 - mae: 16.1007 - val_loss: 371.0974 - val_mae: 15.6556\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 396.4793 - mae: 16.0557 - val_loss: 369.2334 - val_mae: 15.6152\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 394.4899 - mae: 16.0148 - val_loss: 366.9586 - val_mae: 15.5627\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 392.3946 - mae: 15.9692 - val_loss: 365.7896 - val_mae: 15.5407\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 390.3756 - mae: 15.9296 - val_loss: 364.6710 - val_mae: 15.5189\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 388.5334 - mae: 15.8915 - val_loss: 363.0956 - val_mae: 15.4848\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 386.2857 - mae: 15.8454 - val_loss: 360.4963 - val_mae: 15.4223\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 384.4149 - mae: 15.8059 - val_loss: 359.1049 - val_mae: 15.3926\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 382.4593 - mae: 15.7655 - val_loss: 356.6937 - val_mae: 15.3350\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 380.4118 - mae: 15.7206 - val_loss: 355.7368 - val_mae: 15.3170\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 378.5434 - mae: 15.6829 - val_loss: 353.6114 - val_mae: 15.2667\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 376.6266 - mae: 15.6443 - val_loss: 352.0153 - val_mae: 15.2304\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 374.9033 - mae: 15.6107 - val_loss: 351.2517 - val_mae: 15.2180\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 372.9666 - mae: 15.5673 - val_loss: 349.1315 - val_mae: 15.1671\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 371.1592 - mae: 15.5277 - val_loss: 347.5702 - val_mae: 15.1314\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 369.5999 - mae: 15.4941 - val_loss: 347.1506 - val_mae: 15.1260\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 367.8109 - mae: 15.4559 - val_loss: 345.0433 - val_mae: 15.0746\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 366.0948 - mae: 15.4180 - val_loss: 344.0028 - val_mae: 15.0523\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 364.4173 - mae: 15.3839 - val_loss: 342.5008 - val_mae: 15.0163\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 362.7797 - mae: 15.3479 - val_loss: 341.1078 - val_mae: 14.9839\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 361.1746 - mae: 15.3131 - val_loss: 339.1665 - val_mae: 14.9350\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 359.5551 - mae: 15.2763 - val_loss: 337.6967 - val_mae: 14.9000\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 357.8798 - mae: 15.2394 - val_loss: 336.9785 - val_mae: 14.8872\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 356.2517 - mae: 15.2041 - val_loss: 335.0924 - val_mae: 14.8402\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 354.7736 - mae: 15.1704 - val_loss: 333.4751 - val_mae: 14.8020\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 353.0982 - mae: 15.1335 - val_loss: 332.1923 - val_mae: 14.7722\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 351.5634 - mae: 15.1004 - val_loss: 330.3805 - val_mae: 14.7273\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 350.0854 - mae: 15.0700 - val_loss: 330.1280 - val_mae: 14.7286\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 348.5934 - mae: 15.0370 - val_loss: 327.4200 - val_mae: 14.6595\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 346.8205 - mae: 14.9956 - val_loss: 326.3487 - val_mae: 14.6379\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 345.2780 - mae: 14.9622 - val_loss: 325.6286 - val_mae: 14.6255\n",
      "Epoch 148/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 343.8943 - mae: 14.9349 - val_loss: 324.7299 - val_mae: 14.6060\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 342.6707 - mae: 14.9030 - val_loss: 322.5074 - val_mae: 14.5513\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 340.9182 - mae: 14.8677 - val_loss: 322.0516 - val_mae: 14.5450\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 339.4842 - mae: 14.8356 - val_loss: 321.3264 - val_mae: 14.5318\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 338.0034 - mae: 14.8026 - val_loss: 319.7335 - val_mae: 14.4929\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 336.5844 - mae: 14.7704 - val_loss: 318.5999 - val_mae: 14.4677\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 335.2607 - mae: 14.7401 - val_loss: 317.3279 - val_mae: 14.4368\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 333.9356 - mae: 14.7108 - val_loss: 316.5277 - val_mae: 14.4208\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 332.5295 - mae: 14.6806 - val_loss: 315.4216 - val_mae: 14.3945\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 331.1862 - mae: 14.6493 - val_loss: 314.2296 - val_mae: 14.3679\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 329.7515 - mae: 14.6178 - val_loss: 312.6033 - val_mae: 14.3260\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 328.3801 - mae: 14.5831 - val_loss: 311.2024 - val_mae: 14.2921\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 327.1067 - mae: 14.5550 - val_loss: 310.6862 - val_mae: 14.2817\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 325.7773 - mae: 14.5214 - val_loss: 308.8132 - val_mae: 14.2337\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 324.6809 - mae: 14.5052 - val_loss: 309.1495 - val_mae: 14.2503\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 323.1890 - mae: 14.4657 - val_loss: 306.7366 - val_mae: 14.1866\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 321.6971 - mae: 14.4289 - val_loss: 306.0131 - val_mae: 14.1707\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 320.4376 - mae: 14.4008 - val_loss: 305.2555 - val_mae: 14.1582\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 319.1866 - mae: 14.3737 - val_loss: 304.0631 - val_mae: 14.1301\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 317.7969 - mae: 14.3392 - val_loss: 303.0226 - val_mae: 14.1068\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 316.4380 - mae: 14.3102 - val_loss: 302.1751 - val_mae: 14.0891\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 315.2301 - mae: 14.2835 - val_loss: 301.3759 - val_mae: 14.0741\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 313.9032 - mae: 14.2530 - val_loss: 299.4457 - val_mae: 14.0229\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 312.6794 - mae: 14.2237 - val_loss: 299.0657 - val_mae: 14.0189\n",
      "Epoch 172/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 311.3254 - mae: 14.1922 - val_loss: 297.5173 - val_mae: 13.9799\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 310.1753 - mae: 14.1655 - val_loss: 297.2186 - val_mae: 13.9765\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 308.7202 - mae: 14.1339 - val_loss: 295.9930 - val_mae: 13.9483\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 307.5579 - mae: 14.1060 - val_loss: 294.0402 - val_mae: 13.8967\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 306.2848 - mae: 14.0721 - val_loss: 293.3172 - val_mae: 13.8817\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 305.0493 - mae: 14.0483 - val_loss: 292.9435 - val_mae: 13.8791\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 303.8104 - mae: 14.0230 - val_loss: 291.4512 - val_mae: 13.8413\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 302.5684 - mae: 13.9897 - val_loss: 289.7844 - val_mae: 13.7980\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 301.2852 - mae: 13.9630 - val_loss: 289.9985 - val_mae: 13.8116\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 299.9308 - mae: 13.9342 - val_loss: 288.3906 - val_mae: 13.7698\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 298.8773 - mae: 13.9074 - val_loss: 287.1086 - val_mae: 13.7393\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 297.5088 - mae: 13.8790 - val_loss: 286.5706 - val_mae: 13.7294\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 296.2339 - mae: 13.8510 - val_loss: 285.6949 - val_mae: 13.7104\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 295.0636 - mae: 13.8265 - val_loss: 284.9924 - val_mae: 13.6947\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 293.8875 - mae: 13.7978 - val_loss: 282.8726 - val_mae: 13.6410\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 292.5688 - mae: 13.7666 - val_loss: 282.2914 - val_mae: 13.6289\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 291.4894 - mae: 13.7478 - val_loss: 281.8273 - val_mae: 13.6209\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 290.1700 - mae: 13.7174 - val_loss: 280.6682 - val_mae: 13.5925\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 288.9774 - mae: 13.6860 - val_loss: 278.6125 - val_mae: 13.5413\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 287.6999 - mae: 13.6541 - val_loss: 277.9346 - val_mae: 13.5245\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 286.4930 - mae: 13.6316 - val_loss: 277.8051 - val_mae: 13.5260\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 285.3565 - mae: 13.6046 - val_loss: 276.1146 - val_mae: 13.4830\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 284.2656 - mae: 13.5812 - val_loss: 276.0205 - val_mae: 13.4837\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 283.0121 - mae: 13.5521 - val_loss: 274.8636 - val_mae: 13.4568\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 281.7560 - mae: 13.5181 - val_loss: 272.7586 - val_mae: 13.4045\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 280.5616 - mae: 13.4923 - val_loss: 272.4016 - val_mae: 13.3975\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 279.4410 - mae: 13.4693 - val_loss: 272.0347 - val_mae: 13.3911\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 278.5832 - mae: 13.4437 - val_loss: 269.8754 - val_mae: 13.3372\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 277.0646 - mae: 13.4130 - val_loss: 269.1263 - val_mae: 13.3222\n",
      "7/7 [==============================] - 0s 997us/step - loss: 313.2013 - mae: 14.3327\n",
      "7/7 [==============================] - 0s 832us/step\n",
      "7/7 [==============================] - 0s 675us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.332699546813965"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "ann = Sequential(layers=[\n",
    "    Dense(10, input_shape=(5,), activation='relu'),\n",
    "    Dense(3, activation='linear')\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = ann.fit(Xtrain, ytrain, epochs=200,\n",
    "                  batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann.evaluate(Xtest, ytest)\n",
    "\n",
    "ann.predict(Xtest)\n",
    "\n",
    "\n",
    "mean_absolute_error(ytest, ann.predict(Xtest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. What preprocessing techniques did you use? Why?\n",
    "   - OrdinalEncoders for each non numerical column. I did this because the data was not prepared for model processing.\n",
    "2. Describe the fine-tuning process and how you reached your model architecture.\n",
    "   - I tried several different models with different number of layers and neurons. Several ideas were taken from lab assignments. I evaluated model, it gave me satisfying results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 2: CNN (40%)\n",
    "For this task, you will be doing image classification:\n",
    "- First, adapt your best model from Task 1 to work on this task, and\n",
    "fit it on the new data. Then, evaluate its performance.\n",
    "- After that, build a CNN model for image classification.\n",
    "- Compare both models in terms of accuracy, number of parameters and speed of\n",
    "inference (the time the model takes to predict 50 samples).\n",
    "\n",
    "For the given data, you need to do proper data preprocessing and augmentation,\n",
    "data loaders.\n",
    "Then fine-tune your model architecture (number of layers, number of filters,\n",
    "activation function, learning rate, momentum, regularization).\n",
    "\n",
    "### Data\n",
    "You will be working with the data in `triple_mnist.zip` for predicting 3-digit\n",
    "numbers writen in the image. Each image contains 3 digits similar to the\n",
    "following example (whose label is `039`):\n",
    "\n",
    "![example](https://github.com/shaohua0116/MultiDigitMNIST/blob/master/asset/examples/039/0_039.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def split_class(number):\n",
    "    return list(map(int, list(str(number))))\n",
    "\n",
    "\n",
    "def split_one_hot(digit):\n",
    "    return [1 if digit == i else 0 for i in range(10)]\n",
    "\n",
    "labels = []\n",
    "for i in range(10):\n",
    "    labels.append(f\"first{i}\")\n",
    "\n",
    "for i in range(10):\n",
    "    labels.append(f\"mid{i}\")\n",
    "\n",
    "for i in range(10):\n",
    "    labels.append(f\"last{i}\")\n",
    "\n",
    "def parse_dataset(id):\n",
    "    d = []\n",
    "    for classname in os.listdir(os.sep.join(['triple_mnist', id])):\n",
    "        for filename in os.listdir(os.sep.join(['triple_mnist', id, classname])):\n",
    "            classes = list(map(split_one_hot, split_class(classname)))\n",
    "            classes = [item for sublist in classes for item in sublist]\n",
    "            line = {\n",
    "                'class': classes,\n",
    "                'filename': filename,\n",
    "                'path': os.sep.join(['triple_mnist', id, classname, filename]),\n",
    "            }\n",
    "\n",
    "            for lbl, cls in zip(labels, classes):\n",
    "                line[lbl] = cls\n",
    "\n",
    "            d.append(line)\n",
    "\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "\n",
    "traindf = parse_dataset('train')\n",
    "testdf = parse_dataset('test')\n",
    "validatedf = parse_dataset('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>first0</th>\n",
       "      <th>first1</th>\n",
       "      <th>first2</th>\n",
       "      <th>first3</th>\n",
       "      <th>first4</th>\n",
       "      <th>first5</th>\n",
       "      <th>first6</th>\n",
       "      <th>...</th>\n",
       "      <th>last0</th>\n",
       "      <th>last1</th>\n",
       "      <th>last2</th>\n",
       "      <th>last3</th>\n",
       "      <th>last4</th>\n",
       "      <th>last5</th>\n",
       "      <th>last6</th>\n",
       "      <th>last7</th>\n",
       "      <th>last8</th>\n",
       "      <th>last9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0_000.png</td>\n",
       "      <td>triple_mnist\\train\\000\\0_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>10_000.png</td>\n",
       "      <td>triple_mnist\\train\\000\\10_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>11_000.png</td>\n",
       "      <td>triple_mnist\\train\\000\\11_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>12_000.png</td>\n",
       "      <td>triple_mnist\\train\\000\\12_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>13_000.png</td>\n",
       "      <td>triple_mnist\\train\\000\\13_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               class    filename  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   0_000.png   \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  10_000.png   \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  11_000.png   \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  12_000.png   \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  13_000.png   \n",
       "\n",
       "                                path  first0  first1  first2  first3  first4  \\\n",
       "0   triple_mnist\\train\\000\\0_000.png       1       0       0       0       0   \n",
       "1  triple_mnist\\train\\000\\10_000.png       1       0       0       0       0   \n",
       "2  triple_mnist\\train\\000\\11_000.png       1       0       0       0       0   \n",
       "3  triple_mnist\\train\\000\\12_000.png       1       0       0       0       0   \n",
       "4  triple_mnist\\train\\000\\13_000.png       1       0       0       0       0   \n",
       "\n",
       "   first5  first6  ...  last0  last1  last2  last3  last4  last5  last6  \\\n",
       "0       0       0  ...      1      0      0      0      0      0      0   \n",
       "1       0       0  ...      1      0      0      0      0      0      0   \n",
       "2       0       0  ...      1      0      0      0      0      0      0   \n",
       "3       0       0  ...      1      0      0      0      0      0      0   \n",
       "4       0       0  ...      1      0      0      0      0      0      0   \n",
       "\n",
       "   last7  last8  last9  \n",
       "0      0      0      0  \n",
       "1      0      0      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64000 validated image filenames.\n",
      "Found 20000 validated image filenames.\n",
      "Found 16000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "columns = labels\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=None,\n",
    "    x_col=\"path\",\n",
    "    y_col=columns,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(84, 84),\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=testdf,\n",
    "    directory=None,\n",
    "    x_col=\"path\",\n",
    "    y_col=columns,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(84, 84),\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=validatedf,\n",
    "    directory=None,\n",
    "    x_col=\"path\",\n",
    "    y_col=columns,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(84, 84),\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.2390 - accuracy: 0.0418 - val_loss: 24.1946 - val_accuracy: 0.0388\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.2794 - accuracy: 0.0491 - val_loss: 24.9464 - val_accuracy: 0.0434\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 26s 7ms/step - loss: 24.3942 - accuracy: 0.0760 - val_loss: 23.0702 - val_accuracy: 0.0630\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.1957 - accuracy: 0.0630 - val_loss: 22.7165 - val_accuracy: 0.0056\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.7382 - accuracy: 0.0039 - val_loss: 24.6860 - val_accuracy: 0.0066\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 26s 7ms/step - loss: 24.5421 - accuracy: 0.0648 - val_loss: 23.0084 - val_accuracy: 0.0523\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.4335 - accuracy: 0.0637 - val_loss: 25.2591 - val_accuracy: 0.0520\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.2564 - accuracy: 0.0649 - val_loss: 25.8484 - val_accuracy: 0.0537\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 26s 7ms/step - loss: 24.1401 - accuracy: 0.0687 - val_loss: 24.5760 - val_accuracy: 0.0509\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 26s 6ms/step - loss: 24.1519 - accuracy: 0.0597 - val_loss: 24.0880 - val_accuracy: 0.0472\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.models import Sequential\n",
    "\n",
    "ann = Sequential(layers=[\n",
    "    Input((84, 84, 1)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(30, activation='linear')\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = ann.fit(train_generator, epochs=10,\n",
    "                  validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ann\n",
    "ann.save('ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0490 - accuracy: 0.3378 - val_loss: 0.0616 - val_accuracy: 0.3392\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0166 - accuracy: 0.3444 - val_loss: 0.0168 - val_accuracy: 0.2691\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0118 - accuracy: 0.3333 - val_loss: 0.0150 - val_accuracy: 0.3237\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0092 - accuracy: 0.3371 - val_loss: 0.0117 - val_accuracy: 0.3584\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0074 - accuracy: 0.3266 - val_loss: 0.0122 - val_accuracy: 0.3466\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0061 - accuracy: 0.3373 - val_loss: 0.0157 - val_accuracy: 0.3528\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0052 - accuracy: 0.3340 - val_loss: 0.0097 - val_accuracy: 0.3175\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0049 - accuracy: 0.3450 - val_loss: 0.0130 - val_accuracy: 0.3447\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0040 - accuracy: 0.3258 - val_loss: 0.0106 - val_accuracy: 0.4191\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0039 - accuracy: 0.3356 - val_loss: 0.0081 - val_accuracy: 0.2719\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0034 - accuracy: 0.3391 - val_loss: 0.0080 - val_accuracy: 0.3196\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0032 - accuracy: 0.3421 - val_loss: 0.0129 - val_accuracy: 0.3076\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0030 - accuracy: 0.3372 - val_loss: 0.0066 - val_accuracy: 0.3174\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0027 - accuracy: 0.3273 - val_loss: 0.0065 - val_accuracy: 0.3635\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0026 - accuracy: 0.3368 - val_loss: 0.0082 - val_accuracy: 0.3708\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0023 - accuracy: 0.3151 - val_loss: 0.0096 - val_accuracy: 0.4119\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0023 - accuracy: 0.3590 - val_loss: 0.0067 - val_accuracy: 0.2851\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 40s 10ms/step - loss: 0.0024 - accuracy: 0.3440 - val_loss: 0.0090 - val_accuracy: 0.4078\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0021 - accuracy: 0.3524 - val_loss: 0.0069 - val_accuracy: 0.3183\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 39s 10ms/step - loss: 0.0021 - accuracy: 0.3325 - val_loss: 0.0074 - val_accuracy: 0.2889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b8597ad760>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(84, 84, 1)),\n",
    "        Conv2D(16, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(32, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(256),\n",
    "        Dense(100),\n",
    "        Dense(30, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=BinaryCrossentropy(\n",
    "    from_logits=False), metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.3235499858856201\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_generator, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Questions\n",
    "1. What preprocessing techniques did you use? Why?\n",
    "    - *Answer*\n",
    "2. What data augmentation techniques did you use?\n",
    "    - *Answer*\n",
    "3. Describe the fine-tuning process and how you reached your final CNN model.\n",
    "    - *Answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 3: Decision Trees and Ensemble Learning (15%)\n",
    "\n",
    "For the `loan_data.csv` data, predict if the bank should give a loan or not.\n",
    "You need to do the following:\n",
    "- Fine-tune a decision tree on the data\n",
    "- Fine-tune a random forest on the data\n",
    "- Compare their performance\n",
    "- Visualize your DT and one of the trees from the RF\n",
    "\n",
    "For evaluating your models, do $80/20$ train test split.\n",
    "\n",
    "### Data\n",
    "- `credit.policy`: Whether the customer meets the credit underwriting criteria.\n",
    "- `purpose`: The purpose of the loan.\n",
    "- `int.rate`: The interest rate of the loan.\n",
    "- `installment`: The monthly installments owed by the borrower if the loan is funded.\n",
    "- `log.annual.inc`: The natural logarithm of the self-reported annual income of the borrower.\n",
    "- `dti`: The debt-to-income ratio of the borrower.\n",
    "- `fico`: The FICO credit score of the borrower.\n",
    "- `days.with.cr.line`: The number of days the borrower has had a credit line.\n",
    "- `revol.bal`: The borrower's revolving balance.\n",
    "- `revol.util`: The borrower's revolving line utilization rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit.policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int.rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log.annual.inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days.with.cr.line</th>\n",
       "      <th>revol.bal</th>\n",
       "      <th>revol.util</th>\n",
       "      <th>inq.last.6mths</th>\n",
       "      <th>delinq.2yrs</th>\n",
       "      <th>pub.rec</th>\n",
       "      <th>not.fully.paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit.policy             purpose  int.rate  installment  log.annual.inc  \\\n",
       "0              1  debt_consolidation    0.1189       829.10       11.350407   \n",
       "1              1         credit_card    0.1071       228.22       11.082143   \n",
       "2              1  debt_consolidation    0.1357       366.86       10.373491   \n",
       "3              1  debt_consolidation    0.1008       162.34       11.350407   \n",
       "4              1         credit_card    0.1426       102.92       11.299732   \n",
       "\n",
       "     dti  fico  days.with.cr.line  revol.bal  revol.util  inq.last.6mths  \\\n",
       "0  19.48   737        5639.958333      28854        52.1               0   \n",
       "1  14.29   707        2760.000000      33623        76.7               0   \n",
       "2  11.63   682        4710.000000       3511        25.6               1   \n",
       "3   8.10   712        2699.958333      33667        73.2               1   \n",
       "4  14.97   667        4066.000000       4740        39.5               0   \n",
       "\n",
       "   delinq.2yrs  pub.rec  not.fully.paid  \n",
       "0            0        0               0  \n",
       "1            0        0               0  \n",
       "2            0        0               0  \n",
       "3            0        0               0  \n",
       "4            1        0               0  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('loan_data.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. How did the DT compare to the RF in performance? Why?\n",
    "   - _Answer_\n",
    "2. After fine-tuning, how does the max depth in DT compare to RF? Why?\n",
    "   - _Answer_\n",
    "3. What is ensemble learning? What are its pros and cons?\n",
    "   - _Answer_\n",
    "4. Briefly explain 2 types of boosting methods and 2 types of bagging methods.\n",
    "   Which of these categories does RF fall under? - _Answer_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 4: Domain Gap (15%)\n",
    "\n",
    "Evaluate your CNN model from task 2 on SVHN data without retraining your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>first0</th>\n",
       "      <th>first1</th>\n",
       "      <th>first2</th>\n",
       "      <th>first3</th>\n",
       "      <th>first4</th>\n",
       "      <th>first5</th>\n",
       "      <th>first6</th>\n",
       "      <th>...</th>\n",
       "      <th>last0</th>\n",
       "      <th>last1</th>\n",
       "      <th>last2</th>\n",
       "      <th>last3</th>\n",
       "      <th>last4</th>\n",
       "      <th>last5</th>\n",
       "      <th>last6</th>\n",
       "      <th>last7</th>\n",
       "      <th>last8</th>\n",
       "      <th>last9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>svhn\\111.png</td>\n",
       "      <td>111.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>svhn\\113.png</td>\n",
       "      <td>113.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>svhn\\114.png</td>\n",
       "      <td>114.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>svhn\\116.png</td>\n",
       "      <td>116.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>svhn\\120.png</td>\n",
       "      <td>120.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             classes          path filename  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  svhn\\111.png  111.png   \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  svhn\\113.png  113.png   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  svhn\\114.png  114.png   \n",
       "3  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  svhn\\116.png  116.png   \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  svhn\\120.png  120.png   \n",
       "\n",
       "   first0  first1  first2  first3  first4  first5  first6  ...  last0  last1  \\\n",
       "0       0       1       0       0       0       0       0  ...      0      1   \n",
       "1       0       1       0       0       0       0       0  ...      0      0   \n",
       "2       0       1       0       0       0       0       0  ...      0      0   \n",
       "3       0       1       0       0       0       0       0  ...      0      0   \n",
       "4       0       1       0       0       0       0       0  ...      1      0   \n",
       "\n",
       "   last2  last3  last4  last5  last6  last7  last8  last9  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      1      0      0      0      0      0      0  \n",
       "2      0      0      1      0      0      0      0      0  \n",
       "3      0      0      0      0      1      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_data = []\n",
    "\n",
    "for filename in os.listdir('svhn'):\n",
    "    pth = os.sep.join(['svhn', filename])\n",
    "    classname = filename.split(os.sep)[-1].split('_')[0]\n",
    "    classname = classname.split('.')[0]\n",
    "\n",
    "    classes = list(map(split_one_hot, split_class(classname)))\n",
    "    classes = [item for sublist in classes for item in sublist]\n",
    "\n",
    "    line = {\n",
    "        'classes': classes,\n",
    "        'path': pth,\n",
    "        'filename': filename\n",
    "    }\n",
    "\n",
    "    for lbl, cls in zip(labels, classes):\n",
    "        line[lbl] = cls\n",
    "\n",
    "    svhn_data.append(line)\n",
    "\n",
    "svhn_df = pd.DataFrame(svhn_data)\n",
    "svhn_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "svhndataset = ImageDataGenerator()\n",
    "\n",
    "svhn_flow = svhndataset.flow_from_dataframe(\n",
    "    dataframe=svhn_df,\n",
    "    directory=None,\n",
    "    x_col=\"path\",\n",
    "    y_col=columns,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(84, 84),\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 119ms/step - loss: 1.8884 - accuracy: 0.0217\n",
      "\n",
      " Test accuracy: 0.021739130839705467\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(svhn_flow, verbose=1)\n",
    "\n",
    "print('\\n', 'Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Questions\n",
    "1. How did your model perform? Why is it better/worse?\n",
    "    - *Answer*\n",
    "2. What is domain gap in the context of ML?\n",
    "    - *Answer*\n",
    "3. Suggest two ways through which the problem of domain gap can be tackled.\n",
    "    - *Answer*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0705d13f126641cc96e2828b5ea10f55348f2b8684d2bd71620b2fa0b1df1d51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
