{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.7\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.cpu().numpy().transpose((1, 2, 0))\n",
    "\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(image, cmap='binary')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def from_one_hot(one_hot):\n",
    "    # one hot is 30 long\n",
    "    # first 10 are first digit, second 10 are second digit, third 10 are third digit\n",
    "    # each 10 is one-hot encoding of digit\n",
    "    # so we just need to find the index of the max value in each 10\n",
    "    # and then convert to string\n",
    "    digits = []\n",
    "\n",
    "    hots = torch.split(one_hot, 10)\n",
    "    for hot in hots:\n",
    "        digits.append(str(hot.argmax().item()))\n",
    "\n",
    "    return int(\"\".join([str(x) for x in digits]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image dataset\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# import Image\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def target_transform(target):\n",
    "    # print(\"got target \", target)\n",
    "\n",
    "    # apply one-hot encoding\n",
    "    one_hot = torch.zeros(30, device=device)\n",
    "\n",
    "    # target is 3 digit number\n",
    "    target = str(target)\n",
    "    if len(target) < 3:\n",
    "        target = \"0\" * (3 - len(target)) + target\n",
    "\n",
    "    # print(\"transformed target \", target)\n",
    "\n",
    "    digits = [int(x) for x in str(target)]\n",
    "    for i, digit in enumerate(digits):\n",
    "        one_hot[i*10 + digit] = 1\n",
    "\n",
    "    # print(\"one hot \", one_hot)\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def image_transform(image):\n",
    "    # create image tensor from PIL image\n",
    "    image = transforms.ToTensor()(image)\n",
    "\n",
    "    return image.to(device)\n",
    "\n",
    "\n",
    "class CustomImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "\n",
    "        for numberdir in os.listdir(root):\n",
    "            for image in os.listdir(os.path.join(root, numberdir)):\n",
    "                imagepath = os.path.join(numberdir, image)\n",
    "\n",
    "                img = Image.open(os.path.join(root, imagepath))\n",
    "                if self.transform is not None:\n",
    "                    img = self.transform(img)\n",
    "\n",
    "                self.images.append(img)\n",
    "                # self.images.append(os.path.join(numberdir, image))\n",
    "\n",
    "                ndir = int(numberdir)\n",
    "                if self.target_transform is not None:\n",
    "                    ndir = self.target_transform(ndir)\n",
    "\n",
    "                self.targets.append(ndir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        # image = Image.open(os.path.join(self.root, image))\n",
    "        # if self.transform is not None:\n",
    "        #     image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "train_ds = CustomImageFolder(root='triple_mnist/train',\n",
    "                             transform=image_transform,\n",
    "                             target_transform=target_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading batches to gpu\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# preload batches to gpu\n",
    "for i, (images, targets) in enumerate(dataloader):\n",
    "    if i == 0:\n",
    "        print(\"preloading batches to gpu\")\n",
    "    images = images.to(device)\n",
    "    targets = targets.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': \"tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\\n        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')\"}>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "imshow(images[0], title=labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.3030607995390892\n",
      "Time spent for epoch:  2.2549636363983154\n",
      "Epoch 1 - Training loss: 0.23574922509491444\n",
      "Time spent for epoch:  2.051508903503418\n",
      "Epoch 2 - Training loss: 0.20667118401825427\n",
      "Time spent for epoch:  2.07045841217041\n",
      "Epoch 3 - Training loss: 0.19110746946930884\n",
      "Time spent for epoch:  2.069460153579712\n",
      "Epoch 4 - Training loss: 0.18042877389490605\n",
      "Time spent for epoch:  2.0963897705078125\n",
      "Epoch 5 - Training loss: 0.17260856345295905\n",
      "Time spent for epoch:  2.0764424800872803\n",
      "Epoch 6 - Training loss: 0.16670316830277443\n",
      "Time spent for epoch:  2.095419406890869\n",
      "Epoch 7 - Training loss: 0.16221085153520107\n",
      "Time spent for epoch:  2.104339122772217\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = nn.Linear(84*84, 256)\n",
    "        # Write 2 lines to define 2 more linear layers.\n",
    "        # 1 hidden layers with number of neurons numbers: 250 and 100\n",
    "        # 1 output layer that should output 10 neurons, one for each class.\n",
    "        self.hidden2 = nn.Linear(256, 100)\n",
    "        self.output = nn.Linear(100, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the linear layers fc1, fc2, fc3, and fc4\n",
    "        # accepts only flattened input (1D batches)\n",
    "        # while the batch x is of size (batch, 28 * 28)\n",
    "        # define one line to flatten the x to be of size (batch_sz, 28 * 28)\n",
    "        x = x.view(-1, 84*84)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "cnn = Net().to(device)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# train model\n",
    "epochs = 8\n",
    "for e in range(epochs):\n",
    "    time_start = time.time()\n",
    "    running_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = cnn(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e,\n",
    "              running_loss / len(dataloader)))\n",
    "        # print time spent for epoch\n",
    "        print(\"Time spent for epoch: \", time.time() - time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_ps(ps):\n",
    "    # one hot is 30 long\n",
    "    # first 10 are first digit, second 10 are second digit, third 10 are third digit\n",
    "    # each 10 is one-hot encoding of digit\n",
    "    # so we just need to find the index of the max value in each 10\n",
    "    # and then convert to string\n",
    "    digits = []\n",
    "    # ps = ps.numpy()\n",
    "\n",
    "    hots = torch.split(ps, 10)\n",
    "    for hot in hots:\n",
    "        digits.append(str(hot.argmax().item()))\n",
    "\n",
    "    return int(\"\".join([str(x) for x in digits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model\n",
    "\n",
    "# load test dataset\n",
    "test_ds = CustomImageFolder(root='triple_mnist/test',\n",
    "                            transform=image_transform,\n",
    "                            target_transform=target_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        # get predictions\n",
    "        ps = F.softmax(outputs, dim=1)\n",
    "        for i, ps in enumerate(ps):\n",
    "            pred = from_ps(ps)\n",
    "            actual = from_one_hot(labels[i])\n",
    "\n",
    "            if pred == actual:\n",
    "                correct += 1\n",
    "            total += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5173\n"
     ]
    }
   ],
   "source": [
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(cnn.state_dict(), 'triple_mnist_ann_53.pth')\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.hidden1 = nn.Linear(84*84, 256)\n",
    "#         # Write 2 lines to define 2 more linear layers.\n",
    "#         # 1 hidden layers with number of neurons numbers: 250 and 100\n",
    "#         # 1 output layer that should output 10 neurons, one for each class.\n",
    "#         self.hidden2 = nn.Linear(256, 100)\n",
    "#         self.output = nn.Linear(100, 30)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # the linear layers fc1, fc2, fc3, and fc4\n",
    "#         # accepts only flattened input (1D batches)\n",
    "#         # while the batch x is of size (batch, 28 * 28)\n",
    "#         # define one line to flatten the x to be of size (batch_sz, 28 * 28)\n",
    "#         x = x.view(-1, 84*84)\n",
    "#         x = F.relu(self.hidden1(x))\n",
    "#         x = F.relu(self.hidden2(x))\n",
    "#         x = self.output(x)\n",
    "#         return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.22911117224395275\n",
      "Time spent for epoch:  10.778152227401733\n",
      "Epoch 1 - Training loss: 0.1571738863289356\n",
      "Time spent for epoch:  8.586018085479736\n",
      "Epoch 2 - Training loss: 0.14863955402374268\n",
      "Time spent for epoch:  8.593998193740845\n",
      "Epoch 3 - Training loss: 0.14519672967493535\n",
      "Time spent for epoch:  8.632893800735474\n",
      "Epoch 4 - Training loss: 0.14330504210293293\n",
      "Time spent for epoch:  8.62691068649292\n",
      "Epoch 5 - Training loss: 0.1420616999566555\n",
      "Time spent for epoch:  8.601975917816162\n",
      "Epoch 6 - Training loss: 0.14119232438504695\n",
      "Time spent for epoch:  8.609955310821533\n",
      "Epoch 7 - Training loss: 0.14072730828821658\n",
      "Time spent for epoch:  8.625913143157959\n",
      "Epoch 8 - Training loss: 0.140227740123868\n",
      "Time spent for epoch:  8.606963396072388\n",
      "Epoch 9 - Training loss: 0.14015968637168408\n",
      "Time spent for epoch:  8.617933988571167\n"
     ]
    }
   ],
   "source": [
    "# define CNN model\n",
    "# input 84x84\n",
    "# output 30\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 256)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "        self.fc3 = nn.Linear(100, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "cnn = CNN().to(device)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "# train model\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    time_start = time.time()\n",
    "    running_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = cnn(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e,\n",
    "              running_loss / len(dataloader)))\n",
    "        # print time spent for epoch\n",
    "        print(\"Time spent for epoch: \", time.time() - time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9701\n"
     ]
    }
   ],
   "source": [
    "# validate on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        # get predictions\n",
    "        # ps = F.softmax(outputs, dim=1)\n",
    "        ps = outputs\n",
    "        for i, ps in enumerate(ps):\n",
    "            pred = int(from_ps(ps))\n",
    "            actual = int(from_one_hot(labels[i]))\n",
    "\n",
    "            if pred == actual:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "        )\n",
    "        self.out = nn.Linear(16 * 42 * 42, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\"\"\"\n",
    "# save current cnn model\n",
    "# torch.save(cnn.state_dict(), 'triple_mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.out = nn.Linear(128 * 5 * 5, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\"\"\"\n",
    "# torch.save(cnn.state_dict(), 'triple_mnist_cnn_best.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
